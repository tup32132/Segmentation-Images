{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa7167a",
   "metadata": {},
   "source": [
    "# GOOGLE get files\n",
    "\n",
    "!apt-get install gcsfuse -y\n",
    "\n",
    "# create directory\n",
    "!mkdir uh-segmentation-training-mount\n",
    "\n",
    "# mount bucket on directory\n",
    "!gcsfuse --implicit-dirs uh-segmentation-training uh-segmentation-training-mount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d3bba",
   "metadata": {},
   "source": [
    "# GOOGLE see files\n",
    "\n",
    "!ls uh-segmentation-training-mount/data/train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff680c77",
   "metadata": {},
   "source": [
    "# GOOGLE install\n",
    "\n",
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install tensorflow[and-cuda]\n",
    "\n",
    "!pip install pydicom\n",
    "!pip install keras\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Conv2DTranspose,\n",
    "    concatenate, BatchNormalization, Activation\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a2f2a",
   "metadata": {},
   "source": [
    "# GOOGLE gpu check\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target file system\n",
    "\n",
    "# data/\n",
    "# ———> train/\n",
    "# ———> validate/\n",
    "# ———> test/\n",
    "# models/\n",
    "# outputs/\n",
    "# training_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0692ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "SOURCE_DIR = \"data/play\"\n",
    "TARGET_DIR = \"\"\n",
    "COPY_DATA_TO_TARGET = False # make copies of data?\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "MODEL = \"test.keras\" # always .keras\n",
    "\n",
    "TRAIN_IMGS = \"data/train\" \n",
    "TRAIN_MSKS = \"data/train\"\n",
    "VAL_IMGS = \"data/validate\"\n",
    "VAL_MSKS = \"data/validate\"\n",
    "TEST_IMGS = \"data/test\"\n",
    "TEST_MSKS = \"data/test\"\n",
    "# OUTPUT_DIR = \"outputs\"\n",
    "\n",
    "R_TRAIN = 0.8\n",
    "R_VAL = 0.2\n",
    "# R_TEST = 0.0\n",
    "\n",
    "IMG_WIDTH = 512 # this may need to be higher depending on dicom images\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "BATCH_SIZE = 16 # default=16, could be higher if running on cloud\n",
    "BUFFER_SIZE = 100 # depends on training set size\n",
    "\n",
    "STEP = 1e-2 # learning rate, default=1e-4\n",
    "EPOCHS = 2 # does fewer data mean fewer epochs? default=5? 25?\n",
    "LAYERS = 4 # default=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe086e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories\n",
    "\n",
    "if not TARGET_DIR:\n",
    "    TARGET_DIR = os.getcwd()\n",
    "os.makedirs(os.path.join(TARGET_DIR, TRAIN_IMGS), exist_ok=True)\n",
    "os.makedirs(os.path.join(TARGET_DIR, TRAIN_MSKS), exist_ok=True)\n",
    "os.makedirs(os.path.join(TARGET_DIR, VAL_IMGS), exist_ok=True)\n",
    "os.makedirs(os.path.join(TARGET_DIR, VAL_MSKS), exist_ok=True)\n",
    "os.makedirs(os.path.join(TARGET_DIR, TEST_IMGS), exist_ok=True)\n",
    "os.makedirs(os.path.join(TARGET_DIR, TEST_MSKS), exist_ok=True)\n",
    "os.makedirs(os.path.join(TARGET_DIR, MODEL_DIR), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ed01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "class UnequalImageMaskError(Exception): pass\n",
    "try:\n",
    "    if SOURCE_DIR:\n",
    "\n",
    "        img_fs = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.dcm')]\n",
    "        msk_fs = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.npy')]\n",
    "\n",
    "        if len(img_fs) != len(msk_fs):\n",
    "            raise UnequalImageMaskError(\"image and mask list lengths are not equal\")\n",
    "except UnequalImageMaskError as uime:\n",
    "    print(uime)\n",
    "    print(\"checking for multiple masks\")\n",
    "\n",
    "    adds = list()\n",
    "    for f in img_fs:\n",
    "        fname = f.removesuffix('.dcm') # apply more transforms if needed\n",
    "        corr_masknames = [fm for fm in msk_fs if fname.strip() in fm]\n",
    "        if len(corr_masknames) < 1:\n",
    "            raise UnequalImageMaskError(f\"image {f} has no corresponding mask\")\n",
    "        for cm in corr_masknames[1:]:\n",
    "            adds.append(str(f))\n",
    "            print(f\"duplicating {f} in training set\")\n",
    "            # msk_fs.remove(cm)\n",
    "            # print(f\"removing {cm} from training set\")\n",
    "    img_fs.extend(adds)\n",
    "\n",
    "if SOURCE_DIR:\n",
    "    seed = 42\n",
    "    labels = None # we do have classes\n",
    "    train_img_fs, val_img_fs = train_test_split(\n",
    "        sorted(img_fs), \n",
    "        train_size=R_TRAIN, test_size=R_VAL, \n",
    "        random_state=seed,\n",
    "        stratify=labels\n",
    "    )\n",
    "    train_msk_fs, val_msk_fs = train_test_split(\n",
    "        sorted(msk_fs), \n",
    "        train_size=R_TRAIN, test_size=R_VAL, \n",
    "        random_state=seed,\n",
    "        stratify=labels\n",
    "    )\n",
    "\n",
    "    if (len(train_img_fs) != len(train_msk_fs)) or (len(val_img_fs) != len(val_msk_fs)):\n",
    "        raise UnequalImageMaskError(\"image and mask list lengths are **still** not equal\")\n",
    "    \n",
    "\n",
    "if SOURCE_DIR and COPY_DATA_TO_TARGET:\n",
    "    for f in train_img_fs: shutil.copy2(\n",
    "        os.path.join(SOURCE_DIR, f),\n",
    "        os.path.join(TARGET_DIR, TRAIN_IMGS, f)\n",
    "    )\n",
    "    for f in val_img_fs: shutil.copy2(\n",
    "        os.path.join(SOURCE_DIR, f),\n",
    "        os.path.join(TARGET_DIR, VAL_IMGS, f)\n",
    "    )\n",
    "    for f in train_msk_fs: shutil.copy2(\n",
    "        os.path.join(SOURCE_DIR, f),\n",
    "        os.path.join(TARGET_DIR, TRAIN_MSKS, f)\n",
    "    )\n",
    "    for f in val_msk_fs: shutil.copy2(\n",
    "        os.path.join(SOURCE_DIR, f),\n",
    "        os.path.join(TARGET_DIR, VAL_MSKS, f)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC load an image\n",
    "\n",
    "def _load_dicom_and_numpy(image_path, mask_path):\n",
    "    image_path = image_path.numpy().decode('utf-8')\n",
    "    mask_path = mask_path.numpy().decode('utf-8')\n",
    "\n",
    "    # image\n",
    "    ds = pydicom.dcmread(image_path)\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "\n",
    "    # standardize channels\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "    n_channels = img.shape[2]\n",
    "    if n_channels == IMG_CHANNELS: # if correct, do nothing\n",
    "        pass\n",
    "    elif n_channels == 1: # multiply\n",
    "        img = np.tile(img, (1, 1, IMG_CHANNELS))\n",
    "    elif n_channels == 3: # reduce to 1 then multiply\n",
    "        img = np.mean(img, axis=-1, keepdims=True)\n",
    "        img = np.tile(img, (1, 1, IMG_CHANNELS))\n",
    "    elif n_channels < IMG_CHANNELS: # add padding\n",
    "        padding = np.zeros(img.shape[:2] + (IMG_CHANNELS-n_channels,), dtype=img.dtype) \n",
    "        img = np.concatenate([img, padding], axis=-1)\n",
    "    elif n_channels > IMG_CHANNELS: # slice down\n",
    "        img = img[..., :IMG_CHANNELS] \n",
    "\n",
    "    # normalize image\n",
    "    if \"RescaleSlope\" in ds and \"RescaleIntercept\" in ds:\n",
    "        img = img * ds.RescaleSlope + ds.RescaleIntercept\n",
    "    min_val, max_val = np.min(img), np.max(img)\n",
    "    if max_val - min_val > 1e-6: \n",
    "        img = (img - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        img = img - min_val\n",
    "\n",
    "    # mask\n",
    "    mask = np.load(mask_path).astype(np.float32)\n",
    "    mask = np.clip(mask / 255.0, 0.0, 1.0) # ensure mask is binary\n",
    "\n",
    "    # add channel dim\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "def load_and_preprocess(image_path, mask_path):\n",
    "    img, mask = tf.py_function( # wrapper for _load_dicom_and_numpy\n",
    "        _load_dicom_and_numpy,\n",
    "        [image_path, mask_path],\n",
    "        [tf.float32, tf.float32]\n",
    "    )\n",
    "    \n",
    "    img.set_shape([None, None, IMG_CHANNELS])\n",
    "    img = tf.image.resize_with_pad(img, IMG_HEIGHT, IMG_WIDTH)\n",
    "    img.set_shape([IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "\n",
    "    mask.set_shape([None, None, 1])\n",
    "    mask = tf.image.resize_with_pad(mask, IMG_HEIGHT, IMG_WIDTH, method='nearest')\n",
    "    mask.set_shape([IMG_HEIGHT, IMG_WIDTH, 1])\n",
    "    \n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff50103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC augment image\n",
    "\n",
    "def augment_data(img, mask):\n",
    "    if tf.random.uniform(()) > 0.5: # randomly flip image\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32) # randomly rotate 90*\n",
    "    img = tf.image.rot90(img, k=k)\n",
    "    mask = tf.image.rot90(mask, k=k)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline\n",
    "\n",
    "if COPY_DATA_TO_TARGET:\n",
    "    train_image_paths = sorted([os.path.join(TARGET_DIR, TRAIN_IMGS, f) for f in os.listdir(os.path.join(TARGET_DIR, TRAIN_IMGS)) if f.endswith(\".dcm\")])\n",
    "    train_mask_paths = sorted([os.path.join(TARGET_DIR, TRAIN_MSKS, f) for f in os.listdir(os.path.join(TARGET_DIR, TRAIN_MSKS)) if f.endswith(\".npy\")])\n",
    "else:\n",
    "    train_image_paths = sorted([os.path.join(SOURCE_DIR, f) for f in train_img_fs if f.endswith('.dcm')]) # sorted([os.path.join(SOURCE_DIR, f) for f in os.listdir(SOURCE_DIR) if f.endswith(\".dcm\") and f in train_img_fs])\n",
    "    train_mask_paths = sorted([os.path.join(SOURCE_DIR, f) for f in train_msk_fs if f.endswith('.npy')]) # sorted([os.path.join(SOURCE_DIR, f) for f in os.listdir(SOURCE_DIR) if f.endswith(\".npy\") and f in train_msk_fs])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_mask_paths))\n",
    "train_dataset = train_dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.cache() # optional\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE) # unsure how much data you have, hence buffer and batch\n",
    "train_dataset = train_dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation pipeline\n",
    "\n",
    "if COPY_DATA_TO_TARGET:\n",
    "    val_image_paths = sorted([os.path.join(TARGET_DIR, VAL_IMGS, f) for f in os.listdir(os.path.join(TARGET_DIR, VAL_IMGS)) if f.endswith(\".dcm\")])\n",
    "    val_mask_paths = sorted([os.path.join(TARGET_DIR, VAL_MSKS, f) for f in os.listdir(os.path.join(TARGET_DIR, VAL_MSKS)) if f.endswith(\".npy\")])\n",
    "else:\n",
    "    val_image_paths = sorted([os.path.join(SOURCE_DIR, f) for f in val_img_fs if f.endswith('.dcm')]) # sorted([os.path.join(SOURCE_DIR, f) for f in os.listdir(SOURCE_DIR) if f.endswith(\".dcm\") and f in val_img_fs])\n",
    "    val_mask_paths = sorted([os.path.join(SOURCE_DIR, f) for f in val_msk_fs if f.endswith('.npy')]) # sorted([os.path.join(SOURCE_DIR, f) for f in os.listdir(SOURCE_DIR) if f.endswith(\".npy\") and f in val_msk_fs])\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_mask_paths))\n",
    "val_dataset = val_dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c3094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample image\n",
    "\n",
    "for images, masks in train_dataset.take(1):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"sample image\")\n",
    "    plt.imshow(images[0, :, :, 0], cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"sample mask\")\n",
    "    plt.imshow(masks[0, :, :, 0], cmap='gray')\n",
    "\n",
    "    # plt.savefig(f\"view_{1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d65a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "def encoder(inputs, num_filters): # encoder block\n",
    "    c = Conv2D(num_filters, 3, activation='relu', padding='same')(inputs) \n",
    "    c = BatchNormalization()(c)\n",
    "    c = Conv2D(num_filters, 3, activation='relu', padding='same')(c)\n",
    "    p = MaxPooling2D(pool_size=(2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def bottleneck(inputs, num_filters): # final convolution before decoder\n",
    "    b = Conv2D(num_filters, 3, activation='relu', padding='same')(inputs)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = Conv2D(num_filters, 3, activation='relu', padding='same', name=\"final_convolution_before_decoder\")(b)\n",
    "    return b\n",
    "\n",
    "def decoder(inputs, skip_connection, num_filters): # decoder block\n",
    "    d = Conv2DTranspose(num_filters, 2, strides=2, padding='same')(inputs)\n",
    "    d = concatenate([d, skip_connection])\n",
    "    d = Conv2D(num_filters, 3, activation='relu', padding='same')(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Conv2D(num_filters, 3, activation='relu', padding='same')(d)\n",
    "    return d\n",
    "\n",
    "c = {}\n",
    "p = {0: Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))}\n",
    "\n",
    "for layer in range(1, 1 + LAYERS): c[layer], p[layer] = encoder(p[layer-1], 2**(5+layer))\n",
    "\n",
    "d = {0: bottleneck(p[LAYERS], 2**(6+LAYERS))}\n",
    "\n",
    "for layer in range(LAYERS): d[layer+1] = decoder(d[layer], c[LAYERS-layer], 2**(5+LAYERS-layer))\n",
    "\n",
    "model = Model(\n",
    "    inputs=p[0], \n",
    "    outputs=Conv2D(1, 1, padding='same', activation ='sigmoid', name='output_mask')(d[LAYERS]), \n",
    "    name=\"UNET\"\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model look\n",
    "\n",
    "# inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "# c1, p1 = encoder(inputs, 64)\n",
    "# c2, p2 = encoder(p1, 128)\n",
    "# c3, p3 = encoder(p2, 256)\n",
    "# c4, p4 = encoder(p3, 512)\n",
    "\n",
    "# b1 = bottleneck(p4, 1024)\n",
    "\n",
    "# d1 = decoder(b1, c4, 512)\n",
    "# d2 = decoder(d1, c3, 256)\n",
    "# d3 = decoder(d2, c2, 128)\n",
    "# d4 = decoder(d3, c1, 64)\n",
    "\n",
    "# outputs = Conv2D(1, 1, padding='same', activation ='sigmoid', name='output_mask')(d4)\n",
    "# d = Model(inputs=inputs, outputs=outputs, name=\"UNET\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC loss\n",
    "\n",
    "# consider focal loss\n",
    "# dice loss commonly used for segmentation to reduce overlap / account for small foreground object\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "# Adam is default, consider stochastic gradient descent for more control over learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=STEP),\n",
    "    loss=dice_loss,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset, # .take(2)\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "model.save(os.path.join(TARGET_DIR, MODEL_DIR, MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see training\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label=\"training loss\")\n",
    "if 'val_loss' in history.history: \n",
    "    plt.plot(history.history['val_loss'], label=\"validation loss\")\n",
    "plt.title(\"dice loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label=\"training accuracy\")\n",
    "if 'val_accuracy' in history.history: \n",
    "    plt.plot(history.history['val_accuracy'], label=\"validation accuracy\")\n",
    "plt.title(\"pixel accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig(\"history\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "# load trained model\n",
    "trained_model = keras.models.load_model( \n",
    "    os.path.join(TARGET_DIR, MODEL_DIR, MODEL),\n",
    "    custom_objects={\"dice_loss\": dice_loss}\n",
    ")\n",
    "\n",
    "# load and preprocess single image\n",
    "TEST_IMAGE = os.path.join(TARGET_DIR, TEST_IMGS, \"image_0000.dcm\")\n",
    "TEST_MASK = os.path.join(TARGET_DIR, TEST_MSKS, \"image_0000_mask.npy\")\n",
    "\n",
    "ds = pydicom.dcmread(TEST_IMAGE)\n",
    "img = ds.pixel_array.astype(np.float32)\n",
    "img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "img_tensor = tf.convert_to_tensor(img)\n",
    "img_resized = tf.image.resize_with_pad(img_tensor, IMG_HEIGHT, IMG_WIDTH)\n",
    "if \"RescaleSlope\" in ds and \"RescaleIntercept\" in ds:\n",
    "    img_resized = img_resized * ds.RescaleSlope + ds.RescaleIntercept\n",
    "min_val, max_val = np.min(img_resized), np.max(img_resized)\n",
    "if max_val - min_val > 1e-6: \n",
    "    img_normalized = (img_resized - min_val) / (max_val - min_val)\n",
    "else:\n",
    "    img_normalized = img_resized - min_val\n",
    "img_batch = tf.expand_dims(img_normalized, axis=0) # batch of 1\n",
    "\n",
    "# generate gradient heatmap\n",
    "bottleneck = \"final_convolution_before_decoder\"\n",
    "\n",
    "grad_model = Model(\n",
    "    trained_model.inputs,\n",
    "    [trained_model.get_layer(bottleneck).output, trained_model.output]\n",
    ")\n",
    "\n",
    "with tf.GradientTape() as tape: # calculate gradients\n",
    "    bottleneck_output, model_output = grad_model(img_batch)\n",
    "    # \"class score\" is mean of output mask\n",
    "    class_score = tf.reduce_mean(model_output)\n",
    "\n",
    "grads = tape.gradient(class_score, bottleneck_output) # get gradient wrt conv layer\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)) # get weights\n",
    "\n",
    "bottleneck_output = bottleneck_output[0]\n",
    "heatmap = bottleneck_output @ pooled_grads[..., tf.newaxis] # multiply by weights\n",
    "heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "heatmap = heatmap.numpy()\n",
    "\n",
    "# get mask prediction\n",
    "unprocessed_pred_mask = model_output[0].numpy()\n",
    "unprocessed_pred_mask_color = np.uint8(255 * unprocessed_pred_mask)\n",
    "unprocessed_pred_mask_color = cv2.applyColorMap(unprocessed_pred_mask_color, cv2.COLORMAP_JET)\n",
    "pred_mask = (unprocessed_pred_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "# create overlay\n",
    "img_overlay = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "overlay = cv2.cvtColor(img_overlay.astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "overlay_resized = cv2.resize(overlay, (IMG_WIDTH, IMG_HEIGHT))\n",
    "heatmap_resized = cv2.resize(heatmap, (IMG_WIDTH, IMG_HEIGHT))\n",
    "heatmap_color = np.uint8(255 * heatmap_resized)\n",
    "heatmap_color = cv2.applyColorMap(heatmap_color, cv2.COLORMAP_JET)\n",
    "\n",
    "heatmap_overlay = cv2.addWeighted(overlay_resized, 0.7, heatmap_color, 0.3, 0)\n",
    "\n",
    "# find test mask\n",
    "if TEST_MASK and os.path.exists(TEST_MASK):\n",
    "\n",
    "    test_mask = np.load(TEST_MASK).astype(np.float32)\n",
    "    test_mask = np.clip(test_mask / 255.0, 0.0, 1.0)\n",
    "    test_mask = np.expand_dims(test_mask, axis=-1)\n",
    "\n",
    "# find error between true mask and predicted mask\n",
    "    test_mask_resized = cv2.resize(test_mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    test_mask_resized = cv2.normalize(test_mask_resized, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    test_mask_resized = np.expand_dims(test_mask_resized.astype(np.uint8), axis=-1)\n",
    "\n",
    "    true_positive_mask = test_mask_resized & pred_mask\n",
    "    # true_positive_mask = cv2.addWeighted(test_mask_resized, 0.5, pred_mask, 0.5, 0)\n",
    "    false_positive_mask = (test_mask_resized == 0) & pred_mask\n",
    "\n",
    "# display\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(2, 4, 1) # og\n",
    "plt.title(\"xray\") \n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 2) # prediction mask\n",
    "plt.title(\"predicted mask\")\n",
    "plt.imshow(pred_mask, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 3) # heatmap\n",
    "plt.title(\"activation heatmap\")\n",
    "plt.imshow(heatmap_color)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.title(\"heatmap overlay\") # heatmap overlayed on image\n",
    "plt.imshow(heatmap_overlay) \n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 5) # heatmap\n",
    "plt.title(\"probability heatmap\")\n",
    "plt.imshow(unprocessed_pred_mask_color)\n",
    "plt.axis('off')\n",
    "\n",
    "if test_mask is not None:\n",
    "    plt.subplot(2, 4, 6)\n",
    "    plt.title(\"true mask\") # actual mask\n",
    "    plt.imshow(test_mask, cmap='gray') \n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 4, 7)\n",
    "    plt.title(\"predicted true positive\") # predicted mask vs actual mask, correct pixels\n",
    "    plt.imshow(true_positive_mask, cmap='gray') \n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 4, 8)\n",
    "    plt.title(\"predicted false positive\") # predicted mask vs actual mask, mistakenly activated pixels\n",
    "    plt.imshow(false_positive_mask, cmap='gray') \n",
    "    plt.axis('off')\n",
    "\n",
    "# plt.savefig(\"test\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
